---
title: "Bilancia a due piatti: esperimento di taratura"
short_title: "Rapporto di calibrazione"
logo: "unitn_logo.pdf"
logo_height: "1.2cm"
author: "Tommaso Raffaelli"
date: "23-12-2024"
company: "Dipartimento di Ingegneria Industriale - Corso di Statistica"
output: memor::pdf_memo
classoption: a4paper
number_sections: true
libertine: false
toc: true
lof: true
lot: false
header-includes: \usepackage[italian]{babel}
---

```{r setup, echo=F, include=F}
# Caricamento librerie
library(knitr)
library(kableExtra)
library(tidyverse)
library(modelr)
library(purrr)
library(formatR)
library(patchwork)
library(boot)

# Impostazioni output
knitr::opts_chunk$set(
	fig.align  = "center",      # allineamento figure
	fig.dim    = c(5, 3) * 1.2, # rapporto larghezza/altezza e fattore di scala
	out.height = "2.8in",       # altezza effettiva figure
	message    = FALSE,         # sopprimi messaggi
	warning    = FALSE,         # sopprimi warning
	echo       = TRUE,          # mostra i codice dei chunk
	include    = TRUE,          # mostra l'output dei chunk
	tidy       = FALSE,          # formatta il codice dei chunk
  tidy.opts  = list(width.cutoff=I(75)) # massima larghezza codice nei chunk
)

set.seed(181203)
```

\vfill
\begin{small}
Chiave di verifica:   \hfill 877b1af3fb86aea58f44c21692279e76cc770098 
\end{small}

\newpage

# Introduzione

La bilancia a due piatti è uno strumento classico utilizzato per misurare masse, confrontando un oggetto di massa incognita con pesi di massa nota. La precisione di tale strumento dipende dalla corretta taratura, che data dalla relazione tra l'angolo di equilibrio dell'ago ($\delta$) e la differenza di massa ($\Delta F$) tra i due piatti.

Questo esperimento virtuale ha l'obiettivo di raccogliere dati attraverso una serie di misurazioni simulate, analizzarli mediante tecniche di regressione e determinare i parametri caratteristici della bilancia.

Possiamo dividere l'intero processo dell'esperimento in queste fasi:

1.  Pianificazione: Definire una serie di combinazioni di $F1$ e $\Delta F$ per coprire l'intero intervallo operativo della bilancia.

2.  Acquisizione Dati: Per ogni combinazione di $F1$ e $\Delta F$, registrare l'angolo di equilibrio δδ fornito dalla simulazione.

3.  Analisi dei Dati: Applicare una regressione sui dati trasformati, utilizzando la modello fisico e determinare i parametri $a$ e $FM$ che meglio descrivono i dati raccolti.

4.  Valutazione del Modello: Analizzare i residui per valutare la bontà dell'adattamento del modello ai dati.

# Pianificazione dell'esperimento

\label{Pianificazione dell'esperimento}

Come detto in precendenza durante la taratura possiamo modificare due variabili del sistema **forza sul piatto sinistro** che chiameremo `Forza_sx` e **differenza fra i due piatti** che verrà chiamata `Delta_forza`. Deciso questo possiamo generare una tabella di test che verrà data all'operatore che svolgerà le misurazioni necessarie per la calibrazione

Durante l'aquisizione dei dati per la taratura l'operatore può modificare due variabili del sistema:

-   `Forza sul piatto sinisro`
-   `Differenza di forza fra i due piatti`

La prima, `Forza_sx`, varia fra $100$ e $500$ a intervalli di $50$, invece la seconda, `Delta_forza`, varia fra $-50$ e $50$ a intervalli di $5$.

Sapendo tutto questo possiamo creare la tabella di test usando la funzione `expand.grid`.

```{r}
Ord_dati <- expand.grid(
  Forza_sx = seq(100, 500, 50),
  Delta_forza = seq(-50, 50, 5),
  Risultato = NA
) %>% mutate(
  StdOrd = 1:n(),
  RunOrd = sample(n()),
  .before = Forza_sx
) %>% arrange(RunOrd)

# write.csv(Ord_dati, "Test_suite.csv")
```

Definiamo `StdOrd` come ordine in cui `expand.grid` ha generato la tabella e `RunOrd` come una **casualizzazione** di `StdOrd` in modo da ottenere una sequenza di misure casualizzate così da diminurire l'effetto di di possibili variabili modificanti che non vendono considerate nel modello fisico.

Ottenendo la seguente tabella: \ref{tab:tab1}:

```{r tab1}
Ord_dati[1:10,] %>% 
  kable(booktabs=T, caption="Ordine di test") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), position = "center")
```

Ora l'addetto può procedere con l'aquisizione dei dati.

Come si può notare la funzione `expand.grid` mette all'interno della tabella tutte le combinazioni delle due variabili `Forza_sx` e `Delta_forza`, normalmente in un esperimento, non è sempre necessario svolgere tutte le prove possibili poichè possiamo ovviare alla mancanza di dati con metodi dell'analisi statistica, nel caso di questo esperimento essendo virtuale e non richiedendo un' enorme quantità di tempo sono state prese misure per tutte e $192$ le combinazioni all'interno della tabella, in un caso reale questa questione sarebbe da riconsiderare.

# Lettura dei dati

Come è già stato detto durante la \nameref{Pianificazione dell'esperimento} dall'addetto otterremo un file `csv` che possiamo convertire in una tabella \ref{tab:tab1} contenente:

-   `time`
-   `F1`
-   `DF`
-   `angle`

Tabella dei dati ottenuti:

```{r tab2}
Misurazioni <- read.csv("misurazioni.csv", comment="#")

Misurazioni[1:10,] %>% 
  kable(booktabs=T, caption="Ordine di test") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), position = "center")
```

Mettendo a grafico otteniamo:

```{r}
g1 <- Misurazioni %>% 
  ggplot(aes(x=DF, y=angle, group=F1, color=F1)) + 
  geom_line() + 
  geom_point(aes(y=angle)) + 
  scale_color_viridis_b() + 
  theme(legend.position="top")

g2 <- Misurazioni %>% 
  ggplot(aes(x=F1, y=angle, group=DF, color=DF)) + 
  geom_line() + 
  geom_point(aes(y=angle)) + 
  scale_color_viridis_b() + 
  theme(legend.position="top")

g1 + g2
```

# Regressione

Ora che abbiamo i dati possiamo iniziare a fare la regressione, ma prima bisogna fare alcune considerazioni del tipo:

- verifica di normalità e verifica delle anomalie
- selezione dei dati di train

e solo dopo possiamo iniziare la regressione.


## Modello fisico

La regressione seguirà il modello fisico:

\label{Modello fisico}
$$
tan(angle) = a \frac{DF}{2F1 + FM + DF} 
$$ 
questo non è un modello lineare, infatti, per poter regredire i punti dovremmo usare un metodo non lineare, nel nostro caso useremo il metodo dei minimi quadrati.

## Verifica di normalità

Per poter fare in modo che tutti i test che faremo dopo abbiamo valore dobbiamo prima verificare che i punti, su cui svilupperremo il modello, seguano l'ipotesi di normalità.

La normalità possiamo verificarla in vari modi, in particolare useremo un metodo grafico (`grafico quantile-quantile`) e un test statistico (`test di Shapiro`)

```{r}
Misurazioni %>% 
  ggplot(aes(sample=angle)) + 
  geom_qq_line(color="red") +
  geom_qq() 
```

```{r}
shapiro.test(Misurazioni$angle)
```

Il `test di Shapiro` andrebbe sempre seguito da un test delle anomalie, come `test di Choveniet` o `test di Grubb`, per poter assicurare l'accuratezza del test.

```{r}
library(outliers)
grubbs.test(Misurazioni$angle)
```

## Selezione dati di train

Prima di fare la regressione possiamo selezionare alcuni punti da omettere dal set di dati usati per la regressione del modello in modo da poterli usare come verifica del modello.

```{r}
Misurazioni <- Misurazioni %>% 
  mutate(
    train = runif(n()) > 1/4
)

g1 <- Misurazioni %>% 
  filter(!train) %>% 
  ggplot(aes(x=F1, y=angle)) + 
  geom_point()

g1 + wrap_table(Misurazioni[1:10,], space="fixed")
```

## Regressione ai minimi quadrati
\label{Regressione}

Come già detto la regressione non sarà lineare ma useremo il metodo dei minimi quadrati che in *R* si utilizza tramite la funzione `nls`.

La funzione `nls` deve avere come argomenti:

1.  Funzione: Funzione che rappresenta il modello fisico che stimo considerando per la taratura
2.  Start: valore di partenza per le variabili di calibrazione `a` e `FM`
3.  Data set: misurazioni su cui voliamo regredire il modello fisico

Per comodità possiamo fare una funzione che contiene il \nameref{Modello fisico} e ci restituisce l'angolo, dati i parametri.

```{r}
func <- function(F1, DF, a, FM){
  angle <- (a*(DF / 2*F1 + FM + DF))
  return(angle)
}
```

Ora usando la funzione appena dichiarata possiamo effetturare la regressione del modello.

```{r}
reg <- nls(tan(angle) ~ func(F1, DF, a, FM), start=list(a=1, FM=20), data=Misurazioni)
summary(reg)

cor(atan(Misurazioni$angle), predict(reg)) %>% abs()
```

## Analisi dei residui
\label{Residui}

Un buon metodo per capire se un modello sia adeguato al data set che vogliamo regredire è l'analisi dei residui, essi ci permettono ad esempio di capire, nel caso di un modello lineare, se stiamo facendo underfitting o overfitting.

```{r residui}
resid_plot <- function(t, n) {
  t %>% 
    ggplot(aes(x={{n}}, y=atan(resid))) +
    geom_point()
}


Misurazioni %>%  
  add_residuals(reg) %>% 
  add_predictions(reg) %>% {
    (resid_plot(., F1) + resid_plot(., DF)) / 
    (resid_plot(., angle) + resid_plot(., pred)) + 
     resid_plot(., time)
  }
```

Si può notare come nell'grafico dei residui contro l'angolo ci sia un pattern nei punti

## Bootstrap
\label{Bootstrap}

La tecnica di bootstrap ci permette di ricavare le bande di confidenza del nostro modello

```{r}
stats <- function(data){
  fit <- nls(tan(angle) ~ func(F1, DF, a, FM), data=data, start=list(a=1, FM=20))
  fit$m$getPars()
}

stats(Misurazioni)
```

```{r}
Misurazioni.b <- boot(Misurazioni, R=10000, statistic=function(x, i) stats(x[i,]))
```

```{r}
ci <- list(
  a = boot.ci(Misurazioni.b, type="perc", index=1)$percent[4:5],
  FM = boot.ci(Misurazioni.b, type="perc", index=2)$percent[4:5]
)

ci
```

Ottenendo così gli intervalli di confidenza.

# Conclusioni

Dall'analisi dei dati raccolti, è emerso che la regressione applicata non è in grado di rappresentare in modo soddisfacente il comportamento reale osservato durante l’esperimento.
Tutte le informazioni ricavate, il pattern nei \nameref{Residui}, i `p-value` di `a` e `FM` della \nameref{Regressione} e le bande di confidenza ricavate tramite la tecnica di \nameref{Bootstrap} portano a pensare che il problema sia una cattiva regressione.

Le cause di una cattiva regressione possono essere i dati ricavati dall'esperimento o la regressione in sè, questo può significare che non ci sono abbastanza punti, cosa che dubito, o all'interno delle misurazioni ci sono delle anomalie e queste rende la regressione inaccurata, potrebbe essere anche la regressione che non riesce a rappresentare bene tutto quello che succede durante l'acquisizione dei dati

